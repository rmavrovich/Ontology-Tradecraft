name: Ontology Workflow

on:
  push:
    paths:
      - "projects/project-4/assignment/src/data/**"

jobs:
  build-and-validate:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    env:
      PROJECT_ROOT: projects/project-4/assignment

    defaults:
      run:
        working-directory: ${{ env.PROJECT_ROOT }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # needed for diff below

      - name: Detect exactly one newly ADDED file under src/data/**
        id: detect
        shell: bash
        run: |
          BEFORE_SHA="${{ github.event.before }}"
          AFTER_SHA="${{ github.sha }}"

          # Handle first-push edge case
          if [[ "$BEFORE_SHA" == "0000000000000000000000000000000000000000" || -z "$BEFORE_SHA" ]]; then
            if git rev-parse HEAD^ >/dev/null 2>&1; then
              BEFORE_SHA="$(git rev-parse HEAD^)"
            else
              BEFORE_SHA="$AFTER_SHA"
            fi
          fi

          echo "Diff range: $BEFORE_SHA..$AFTER_SHA"

          ADDED=$(git diff --name-status "$BEFORE_SHA" "$AFTER_SHA" -- "projects/project-4/assignment/src/data/**" | awk '$1=="A"{print $2}')
          COUNT=$(echo "$ADDED" | wc -w)
          ONE_FILE=$(echo "$ADDED" | head -n 1)

          echo "added_count=$COUNT" >> "$GITHUB_OUTPUT"
          if [[ "$COUNT" == "1" ]]; then
            echo "one_file=$ONE_FILE" >> "$GITHUB_OUTPUT"
          fi

      - name: Skip if no new dataset
        if: steps.detect.outputs.added_count == '0'
        run: echo "No brand-new files under src/data/. Skipping."

      - name: Fail if more than one new dataset added
        if: steps.detect.outputs.added_count != '0' && steps.detect.outputs.added_count != '1'
        run: |
          echo "This workflow handles exactly ONE new dataset per push."
          echo "Found: ${{ steps.detect.outputs.added_count }} files added under src/data/."
          exit 1

      - name: Setup Python
        if: steps.detect.outputs.added_count == '1'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        if: steps.detect.outputs.added_count == '1'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || pip install pandas rdflib pyshacl

      - name: Run ETL
        if: steps.detect.outputs.added_count == '1'
        run: python src/scripts/normalize_readings.py

      - name: Build RDF (CCO design pattern)
        if: steps.detect.outputs.added_count == '1'
        run: python src/scripts/measure_rdflib.py

      - name: SPARQL QC (Final Fix - No UNION)
        if: steps.detect.outputs.added_count == '1'
        run: |
          python - << 'PY'
from rdflib import Graph
from pathlib import Path
import sys
  
# Determine the path to the TTL file based on the workflow's working directory setting
TTL = Path("src/measure_cco.ttl")
  
try:
    assert TTL.exists(), f"❌ src/measure_cco.ttl not found at {TTL.resolve()}"
    g = Graph(); g.parse(TTL, format="turtle")
    print(f"[ttl] triples: {len(g)}")
except AssertionError as e:
    print(e)
    sys.exit(2) 
except Exception as e:
    print(f"❌ Error loading TTL file: {e}")
    sys.exit(1)
  
# Exact IRIs to enforce
IRI_SDC   = "http://purl.obolibrary.org/obo/BFO_0000020"
IRI_ART   = "https://www.commoncoreontologies.org/ont00000995"
IRI_MU    = "https://www.commoncoreontologies.org/ont00000120"
IRI_MICE  = "https://www.commoncoreontologies.org/ont00001163"
  
IRI_BEARER_OF   = "http://purl.obolibrary.org/obo/BFO_0000196"
IRI_IS_MEASURE_OF = "https://www.commoncoreontologies.org/ont00001966"
IRI_USES_MU       = "https://www.commoncoreontologies.org/ont00001863"
  
# 1) Type Check
q_types = f"""
SELECT (COUNT(DISTINCT ?a) AS ?A) (COUNT(DISTINCT ?s) AS ?S) (COUNT(DISTINCT ?m) AS ?M) (COUNT(DISTINCT ?u) AS ?U)
WHERE {{
  OPTIONAL {{ ?a a <{IRI_ART}> . }}
  OPTIONAL {{ ?s a <{IRI_SDC}> . }}
  OPTIONAL {{ ?m a <{IRI_MICE}> . }}
  OPTIONAL {{ ?u a <{IRI_MU}> . }}
}}
"""
A,S,M,U = [int(x) for x in list(g.query(q_types.strip()))[0]]
assert all(v>0 for v in (A,S,M,U)), f"❌ Missing required typed nodes: Artifact={A}, SDC={S}, MICE={M}, MU={U}"
print(f"✅ Types present with exact IRIs: Artifact={A}, SDC={S}, MICE={M}, MU={U}")
  
# 2) Pattern Check
q_pattern_strict = f"""
ASK {{
  ?a a <{IRI_ART}> ; <{IRI_BEARER_OF}> ?sdc .
  ?sdc a <{IRI_SDC}> .
  ?m a <{IRI_MICE}> ; <{IRI_IS_MEASURE_OF}> ?sdc ; <{IRI_USES_MU}> ?u .
  ?u a <{IRI_MU}> .
}}
"""
assert bool(g.query(q_pattern_strict.strip()).askAnswer), "❌ No complete pattern found with exact property IRIs."
print("✅ Complete pattern found with exact property IRIs.")
  
# 3) All MICE Check (Final fix: two separate queries to avoid UNION bug)
q_missing_measure_of = f"""
SELECT DISTINCT ?m WHERE {{
  ?m a <{IRI_MICE}> .
  FILTER NOT EXISTS {{ ?m <{IRI_IS_MEASURE_OF}> ?sdc . ?sdc a <{IRI_SDC}> . }}
}}
"""
  
q_missing_unit = f"""
SELECT DISTINCT ?m WHERE {{
  ?m a <{IRI_MICE}> .
  FILTER NOT EXISTS {{ ?m <{IRI_USES_MU}> ?u . ?u a <{IRI_MU}> . }}
}}
"""
  
# Execute queries and combine results in Python
bad_mice = set()
bad_mice.update(list(g.query(q_missing_measure_of.strip())))
bad_mice.update(list(g.query(q_missing_unit.strip())))
  
n_bad = len(bad_mice)
assert n_bad == 0, f"❌ Some MICE are missing required links with the exact IRIs (count={n_bad})."
print("✅ All MICE use exact IRIs for 'is measure of' and 'uses measurement unit'.")
  
print("✅ RDF passes exact-IRI checks for the measurement design pattern.")
sys.exit(0)
          PY

      - name: SHACL validation
        if: steps.detect.outputs.added_count == '1'
        run: python src/scripts/run_shacl.py
